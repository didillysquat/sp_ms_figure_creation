{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Ed's .fastq files that contain both psbAncr sequences and ITS2 sequences to fastq that only contain ITS2 sequences.\n",
    "The aim of this notebook is to document the above process. Originally when Ed did his sequencing for the Smith et al 2018 project each paired fastq file contained the psbancr and ITS2 sequence for each sample. We want to remove the psbAncr sequences so that we end up with fastq files that we can put through SymPortal. This data will be used as the example dataset for SymPortal's online wiki as well.\n",
    "\n",
    "In order to remove the psbAncr sequences we will esentially run mothur to look for the fwd and rev ITS2 primers which are the SYM_VAR_5.8S2 and SYM_VAR_REV primers. We will use mothur to do this and we will allow the filtering to be quite sloppy by setting ```pdiff=3``` ```rdiff=3```. It is also worth noticing the Ed's sequences are currently reverse complement.\n",
    "\n",
    "#### To process the raw .fastq files:\n",
    "1. Unzip the .fastq.gz files to new directory (mothur will throw up errors if the files remain compressed)\n",
    "2. Process the .fastq files through mothur on the command line\n",
    "3. Use the name file created from the mothur processing to identify sequences to keep for the new fastq files.\n",
    "4. Recompress the output .fastq files to .fastq.gz files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Unzip the .fastq.gz files to new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -dk *.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv *.fastq ./unzipped/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Process the .fastq files through mothur on the command line\n",
    "Copy the following into a batch __file called mothur_batch_file__:\n",
    "```console\n",
    "make.file(inputdir=/home/humebc/projects/SymPortalMS/making_example_data_set/SP_DEMO_DATA/unzipped/)\n",
    "make.contigs(file=stability.files, processors=26)\n",
    "unique.seqs(fasta=stability.trim.contigs.fasta)\n",
    "reverse.seqs(fasta=stability.trim.contigs.unique.fasta)\n",
    "pcr.seqs(fasta=stability.trim.contigs.unique.rc.fasta, name=stability.trim.contigs.names, oligos=primers.oligos, pdiffs=3, rdiffs=3)\n",
    "```\n",
    "Copy the following into a file named __primers.oligos__:\n",
    "```console\n",
    "#SYM_VAR_5.8S2\n",
    "forward GAATTGCAGAACTCCGTGAACC\n",
    "#SYM_VAR_REV\n",
    "reverse CGGGTTCWCTTGTYTGACTTCATGC\n",
    "```\n",
    "Run the batch file by passing it as an argument to mothur:\n",
    "```console\n",
    "$ mothur mothur_batch_file\n",
    "```\n",
    "This should give you the following file output: __stability.trim.contigs.pcr.names__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the name file created from the mothur processing to identify sequences to keep for the new fastq files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the python environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from multiprocessing import Queue, Process, Manager\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of the fastq files that we are working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkd = os.path.dirname(__file__) + '/unzipped'\n",
    "    file_names = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(wkd):\n",
    "        file_names.extend(filenames)\n",
    "        break\n",
    "\n",
    "    list_of_fastqs = [file for file in file_names if '.fastq' in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of the of the sequences that have come through the mothur processing from the .names file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_name_file = readDefinedFileToList('{}/stability.trim.contigs.pcr.names'.format(wkd))\n",
    "    list_of_seq_names = []\n",
    "    for i in range(len(pcr_name_file)):\n",
    "        list_of_seq_names.extend([name[2:] for name in pcr_name_file[i].split('\\t')[1].split(',')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the multiprocessing envrionment (it will take ages to do it in a serialized manner):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskQueue = Queue()\n",
    "\n",
    "for fastq_file in list_of_fastqs:\n",
    "    taskQueue.put(fastq_file)\n",
    "\n",
    "for n in range(24):\n",
    "    taskQueue.put('STOP')\n",
    "\n",
    "allProcesses = []\n",
    "\n",
    "\n",
    "for n in range(24):\n",
    "    p = Process(target=worker_screen, args=(taskQueue, wkd, list_of_seq_names))\n",
    "    allProcesses.append(p)\n",
    "    p.start()\n",
    "\n",
    "for p in allProcesses:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the worker for the multiprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_screen(input, wkd, list_of_seq_names):\n",
    "    # now we have a list of the seqs that we want to keep\n",
    "    # for each of the fastqs go through and only keep the sequences that are found in this list\n",
    "    for fastq_file in iter(input.get, 'STOP'):\n",
    "        # track which file is currently being processed\n",
    "        print('Processing {}'.format(fastq_file))\n",
    "        \n",
    "        # list that will hold the records to keep\n",
    "        list_of_records_to_keep = []\n",
    "        \n",
    "        # use the SeqIO to easily parse through the fastq format rather than reinventing wheel\n",
    "        records = list(SeqIO.parse('{}/{}'.format(wkd, fastq_file), \"fastq\"))\n",
    "        # track the number of records processed\n",
    "        count = 0\n",
    "        # count the number of sequences kept\n",
    "        counter = 0\n",
    "        # denominator for progress output\n",
    "        length = len(records)\n",
    "        \n",
    "        # for each sequence in the fastq file that is currently being processed\n",
    "        for record in records:\n",
    "            count += 1\n",
    "            # print status ever 1000 seqs processed\n",
    "            if count % 1000 == 0:\n",
    "                print('{}: {} complete; {} records found'.format(fastq_file, count/length, counter))\n",
    "            # check to see if the record has one of the 'names to keep' strings in it\n",
    "            if record.description[2:-2] in list_of_seq_names:\n",
    "                # if so, add to keep list\n",
    "                list_of_records_to_keep.append(record)\n",
    "                counter += 1\n",
    "        # write out the new file with '_its2_only.fastq' appended to file name\n",
    "        with open(\"{}/{}_its2_only.fastq\".format(wkd, fastq_file.replace('.fastq', '')), \"w\") as output_handle:\n",
    "            SeqIO.write(list_of_records_to_keep, output_handle, \"fastq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__N.B.__ the above code takes about 20 mins to run for the 45 or so samples that Ed has in his dataset. If this coder were to be re-used at a larger scale it could be make much faster by working on a sample by sample basis for the mothur processing and then continuing on a sample by sample basis for the MPing with a list_of_seq_names for each sample. As it is the list_of_seq_names contains the seq names that passed through mothur for all of the samples. It is therefore quite a lot of work to search through this list each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Recompress the output .fastq files to .fastq.gz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd unzipped/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip *.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The set of fastq.gz files now only contain the ITS2 sequences and we can use this set of files as a direct input into the SymPortal data_set submission.__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
